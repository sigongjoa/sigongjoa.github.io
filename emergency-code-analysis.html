<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>ì‘ê¸‰êµ¬ì¡° ìˆ˜ìš” ì˜ˆì¸¡ - ì½”ë“œ ë¶„ì„ | ì„œì¬ìš©</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script>
        tailwind.config = {
            theme: { 
                extend: { 
                    colors: { 
                        primary: '#1F3A93',
                        'code-bg': '#1e1e1e',
                        'code-sidebar': '#252526',
                        'code-active': '#094771'
                    } 
                } 
            }
        }
        console.log("ERROR: emergency_code_analysis.js:line_12 - IDE ìŠ¤íƒ€ì¼ ì½”ë“œ ë¶„ì„ í˜ì´ì§€ ë¡œë“œë¨");
    </script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/styles/vs2015.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.9.0/highlight.min.js"></script>
</head>
<body class="bg-code-bg text-gray-100 font-mono">
    <!-- Header -->
    <header class="bg-code-sidebar border-b border-gray-700 px-6 py-3">
        <div class="flex items-center justify-between">
            <div class="flex items-center space-x-4">
                <h1 class="text-lg font-semibold text-white">ì‘ê¸‰êµ¬ì¡° ìˆ˜ìš” ì˜ˆì¸¡ - ì½”ë“œ ë¶„ì„</h1>
                <span class="text-xs text-gray-400">TFT ëª¨ë¸ ê¸°ë°˜ ì‹œê³µê°„ ë°ì´í„° í•™ìŠµ</span>
            </div>
            <div class="flex items-center space-x-4">
                <button onclick="searchFiles()" class="text-gray-400 hover:text-white text-sm">
                    Ctrl+P íŒŒì¼ ê²€ìƒ‰
                </button>
                <a href="emergency-forecast.html" class="text-blue-400 hover:text-blue-300 text-sm">
                    â† í”„ë¡œì íŠ¸ë¡œ ëŒì•„ê°€ê¸°
                </a>
            </div>
        </div>
    </header>

    <div class="flex h-screen">
        <!-- Sidebar: Project File Tree -->
        <div class="SidebarContainer w-80 bg-code-sidebar border-r border-gray-700 overflow-y-auto">
            <div class="SidebarHeader p-4 border-b border-gray-700">
                <h2 class="text-sm font-semibold text-gray-300 uppercase tracking-wide">
                    ğŸ“ ì‘ê¸‰êµ¬ì¡° ìˆ˜ìš” ì˜ˆì¸¡ í”„ë¡œì íŠ¸
                </h2>
            </div>
            
            <div class="FileTreeContainer p-2">
                <!-- Main Project Files -->
                <div class="FileTreeLevel1">
                    <div class="FolderItem cursor-pointer hover:bg-gray-700 p-2 rounded" onclick="toggleFolder('src')">
                        <span class="text-yellow-400">ğŸ“‚</span>
                        <span class="ml-2 text-gray-300">src/</span>
                    </div>
                    <div id="src-folder" class="FolderContent ml-4">
                        <div class="FileItem cursor-pointer hover:bg-gray-700 p-1 rounded text-sm" onclick="loadFile('main.py')">
                            <span class="text-blue-400">ğŸ</span>
                            <span class="ml-2 text-gray-300">main.py</span>
                        </div>
                        <div class="FileItem cursor-pointer hover:bg-gray-700 p-1 rounded text-sm" onclick="loadFile('emergency_data_processor.py')">
                            <span class="text-blue-400">ğŸ</span>
                            <span class="ml-2 text-gray-300">emergency_data_processor.py</span>
                        </div>
                        <div class="FileItem cursor-pointer hover:bg-gray-700 p-1 rounded text-sm" onclick="loadFile('tft_model.py')">
                            <span class="text-blue-400">ğŸ</span>
                            <span class="ml-2 text-gray-300">tft_model.py</span>
                        </div>
                        <div class="FileItem cursor-pointer hover:bg-gray-700 p-1 rounded text-sm" onclick="loadFile('spatial_features.py')">
                            <span class="text-blue-400">ğŸ</span>
                            <span class="ml-2 text-gray-300">spatial_features.py</span>
                        </div>
                        <div class="FileItem cursor-pointer hover:bg-gray-700 p-1 rounded text-sm" onclick="loadFile('weather_integration.py')">
                            <span class="text-blue-400">ğŸ</span>
                            <span class="ml-2 text-gray-300">weather_integration.py</span>
                        </div>
                        <div class="FileItem cursor-pointer hover:bg-gray-700 p-1 rounded text-sm" onclick="loadFile('visualization.py')">
                            <span class="text-blue-400">ğŸ</span>
                            <span class="ml-2 text-gray-300">visualization.py</span>
                        </div>
                        <div class="FileItem cursor-pointer hover:bg-gray-700 p-1 rounded text-sm" onclick="loadFile('model_evaluation.py')">
                            <span class="text-blue-400">ğŸ</span>
                            <span class="ml-2 text-gray-300">model_evaluation.py</span>
                        </div>
                    </div>
                </div>

                <!-- Data Processing -->
                <div class="FileTreeLevel1">
                    <div class="FolderItem cursor-pointer hover:bg-gray-700 p-2 rounded" onclick="toggleFolder('data')">
                        <span class="text-yellow-400">ğŸ“‚</span>
                        <span class="ml-2 text-gray-300">data/</span>
                    </div>
                    <div id="data-folder" class="FolderContent ml-4 hidden">
                        <div class="FileItem cursor-pointer hover:bg-gray-700 p-1 rounded text-sm" onclick="loadFile('data_loader.py')">
                            <span class="text-blue-400">ğŸ</span>
                            <span class="ml-2 text-gray-300">data_loader.py</span>
                        </div>
                        <div class="FileItem cursor-pointer hover:bg-gray-700 p-1 rounded text-sm" onclick="loadFile('preprocessing.py')">
                            <span class="text-blue-400">ğŸ</span>
                            <span class="ml-2 text-gray-300">preprocessing.py</span>
                        </div>
                    </div>
                </div>

                <!-- Configuration -->
                <div class="FileTreeLevel1">
                    <div class="FolderItem cursor-pointer hover:bg-gray-700 p-2 rounded" onclick="toggleFolder('config')">
                        <span class="text-yellow-400">ğŸ“‚</span>
                        <span class="ml-2 text-gray-300">config/</span>
                    </div>
                    <div id="config-folder" class="FolderContent ml-4 hidden">
                        <div class="FileItem cursor-pointer hover:bg-gray-700 p-1 rounded text-sm" onclick="loadFile('settings.py')">
                            <span class="text-blue-400">ğŸ</span>
                            <span class="ml-2 text-gray-300">settings.py</span>
                        </div>
                        <div class="FileItem cursor-pointer hover:bg-gray-700 p-1 rounded text-sm" onclick="loadFile('requirements.txt')">
                            <span class="text-green-400">ğŸ“„</span>
                            <span class="ml-2 text-gray-300">requirements.txt</span>
                        </div>
                    </div>
                </div>

                <!-- Notebooks -->
                <div class="FileTreeLevel1">
                    <div class="FolderItem cursor-pointer hover:bg-gray-700 p-2 rounded" onclick="toggleFolder('notebooks')">
                        <span class="text-yellow-400">ğŸ“‚</span>
                        <span class="ml-2 text-gray-300">notebooks/</span>
                    </div>
                    <div id="notebooks-folder" class="FolderContent ml-4 hidden">
                        <div class="FileItem cursor-pointer hover:bg-gray-700 p-1 rounded text-sm" onclick="loadFile('eda.ipynb')">
                            <span class="text-orange-400">ğŸ““</span>
                            <span class="ml-2 text-gray-300">eda.ipynb</span>
                        </div>
                        <div class="FileItem cursor-pointer hover:bg-gray-700 p-1 rounded text-sm" onclick="loadFile('model_training.ipynb')">
                            <span class="text-orange-400">ğŸ““</span>
                            <span class="ml-2 text-gray-300">model_training.ipynb</span>
                        </div>
                    </div>
                </div>
            </div>
        </div>

        <!-- Main Editor Area -->
        <div class="EditorContainer flex-1 flex flex-col">
            <!-- Tab Bar -->
            <div class="TabBar bg-code-sidebar border-b border-gray-700 px-4 py-2">
                <div class="flex space-x-2">
                    <div id="active-tab" class="bg-code-active text-white px-4 py-1 rounded-t text-sm">
                        main.py
                    </div>
                </div>
            </div>

            <!-- Editor Content -->
            <div class="EditorContent flex-1 overflow-auto">
                <div class="LineNumbers bg-gray-800 text-gray-500 text-xs leading-6 p-4 float-left min-w-12 text-right">
                    <div id="line-numbers">1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>29<br>30<br>31<br>32<br>33<br>34<br>35<br>36<br>37<br>38<br>39<br>40<br>41<br>42<br>43<br>44<br>45<br>46<br>47<br>48<br>49<br>50<br>51<br>52<br>53<br>54<br>55<br>56<br>57<br>58<br>59<br>60<br>61<br>62<br>63<br>64<br>65<br>66<br>67<br>68<br>69<br>70<br>71<br>72<br>73<br>74<br>75<br>76<br>77<br>78<br>79<br>80<br>81<br>82<br>83<br>84<br>85<br>86<br>87<br>88<br>89<br>90</div>
                </div>
                <div class="CodeArea flex-1 p-4 overflow-x-auto">
                    <pre id="code-display" class="text-sm leading-6"><code class="python" id="code-content">"""
ì§€ëŠ¥í˜• êµ¬ê¸‰ìˆ˜ìš” ì˜ˆì¸¡ì‹œìŠ¤í…œ ë©”ì¸ ëª¨ë“ˆ
ì‹œê³µê°„ ë°ì´í„° í•™ìŠµì„ ì´ìš©í•œ ë”¥ëŸ¬ë‹ ê¸°ë°˜ êµí†µì‚¬ê³  ìœ„í—˜ ì˜ˆì¸¡

Author: ì„œì¬ìš©
Project: ê°•ì›ë„ ì†Œë°©ë³¸ë¶€ ì‘ê¸‰êµ¬ì¡° ìˆ˜ìš” ì˜ˆì¸¡
Date: 2021-2023
"""

import sys
import os
import pandas as pd
import numpy as np
import torch
import warnings
from datetime import datetime
from pathlib import Path

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ ì„í¬íŠ¸
from src.emergency_data_processor import EmergencyDataProcessor
from src.tft_model import EmergencyDemandPredictor
from src.spatial_features import SpatialFeatureExtractor
from src.weather_integration import WeatherDataIntegrator
from src.visualization import EmergencyAnalyzer
from src.model_evaluation import ModelEvaluator
from config.settings import CONFIG

# ê²½ê³  ë©”ì‹œì§€ ìˆ¨ê¸°ê¸°
warnings.filterwarnings('ignore')

# ë””ë²„ê·¸ ë¡œê¹… ì„¤ì •
import logging
logging.basicConfig(level=logging.ERROR, format='ERROR: %(name)s:line_%(lineno)d - %(message)s')
logger = logging.getLogger(__name__)

class EmergencyForecastSystem:
    """ì‘ê¸‰êµ¬ì¡° ìˆ˜ìš” ì˜ˆì¸¡ ì‹œìŠ¤í…œ ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.config = CONFIG
        self.data_processor = EmergencyDataProcessor()
        self.spatial_extractor = SpatialFeatureExtractor()
        self.weather_integrator = WeatherDataIntegrator()
        self.predictor = EmergencyDemandPredictor(
            max_encoder_length=self.config['model']['encoder_length'],
            max_prediction_length=self.config['model']['prediction_length']
        )
        self.analyzer = EmergencyAnalyzer()
        self.evaluator = ModelEvaluator()
        
        logger.error("ì‘ê¸‰êµ¬ì¡° ìˆ˜ìš” ì˜ˆì¸¡ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
        
    def load_and_process_data(self):
        """ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
        logger.error("ë°ì´í„° ë¡œë“œ ì‹œì‘")
        
        # ê°•ì›ë„ ì†Œë°©ì¼ì§€ ë°ì´í„° ë¡œë“œ
        fire_data = self.data_processor.load_fire_department_data(
            self.config['data']['fire_department_path']
        )
        
        # ê³µê°„ì  íŠ¹ì„± ì¶”ê°€
        fire_data = self.spatial_extractor.add_spatial_features(fire_data)
        
        # ë‚ ì”¨ ë°ì´í„° í†µí•©
        fire_data = self.weather_integrator.integrate_weather_data(
            fire_data, self.config['data']['weather_path']
        )
        
        # ì‹œê³„ì—´ íŠ¹ì„± ìƒì„±
        processed_data = self.data_processor.create_time_series_features(fire_data)
        
        logger.error(f"ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ - ì´ {len(processed_data)}ê°œ ë ˆì½”ë“œ")
        return processed_data
        
    def train_model(self, data):
        """TFT ëª¨ë¸ í•™ìŠµ"""
        logger.error("TFT ëª¨ë¸ í•™ìŠµ ì‹œì‘")
        
        # í›ˆë ¨/ê²€ì¦ ë°ì´í„° ë¶„í• 
        train_data = data[data['date'] < self.config['data']['split_date']]
        val_data = data[data['date'] >= self.config['data']['split_date']]
        
        # ì‹œê³„ì—´ ë°ì´í„°ì…‹ ìƒì„±
        training_dataset = self.predictor.create_dataset(train_data)
        validation_dataset = self.predictor.create_dataset(val_data)
        
        # ë°ì´í„°ë¡œë” ìƒì„±
        train_dataloader = training_dataset.to_dataloader(
            train=True, batch_size=self.config['model']['batch_size']
        )
        val_dataloader = validation_dataset.to_dataloader(
            train=False, batch_size=self.config['model']['batch_size']
        )
        
        # TFT ëª¨ë¸ êµ¬ì¶• ë° í•™ìŠµ
        model = self.predictor.build_model(training_dataset)
        trainer = self.predictor.train_model(
            train_dataloader, val_dataloader, 
            max_epochs=self.config['model']['max_epochs']
        )
        
        logger.error("TFT ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")
        return model, trainer, validation_dataset

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    logger.error("ì‘ê¸‰êµ¬ì¡° ìˆ˜ìš” ì˜ˆì¸¡ ì‹œìŠ¤í…œ ì‹œì‘")
    
    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    system = EmergencyForecastSystem()
    
    # ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
    data = system.load_and_process_data()
    
    # ëª¨ë¸ í•™ìŠµ
    model, trainer, val_dataset = system.train_model(data)
    
    # ëª¨ë¸ í‰ê°€
    predictions = system.predictor.predict_emergency_demand(val_dataset)
    metrics = system.evaluator.evaluate_predictions(predictions, val_dataset)
    
    # ê²°ê³¼ ì‹œê°í™”
    system.analyzer.create_comprehensive_report(predictions, metrics)
    
    logger.error("ì‘ê¸‰êµ¬ì¡° ìˆ˜ìš” ì˜ˆì¸¡ ì‹œìŠ¤í…œ ì‹¤í–‰ ì™„ë£Œ")
    print("ğŸš€ ì‘ê¸‰êµ¬ì¡° ìˆ˜ìš” ì˜ˆì¸¡ ì‹œìŠ¤í…œì´ ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤!")

if __name__ == "__main__":
    main()
</code></pre>
                </div>
            </div>
        </div>
    </div>

    <!-- Status Bar -->
    <div class="StatusBar bg-blue-600 text-white px-4 py-1 text-xs">
        <div class="flex justify-between items-center">
            <div class="flex space-x-4">
                <span>ğŸ”¥ ì‘ê¸‰êµ¬ì¡° ìˆ˜ìš” ì˜ˆì¸¡</span>
                <span>Python 3.8.10</span>
                <span>UTF-8</span>
                <span>LF</span>
            </div>
            <div class="flex space-x-4">
                <span>Ln 1, Col 1</span>
                <span>ğŸš€ TFT ëª¨ë¸ ì¤€ë¹„ë¨</span>
            </div>
        </div>
    </div>

    <!-- File Content Database -->
    <script>
        const fileContents = {
            'main.py': `"""
ì§€ëŠ¥í˜• êµ¬ê¸‰ìˆ˜ìš” ì˜ˆì¸¡ì‹œìŠ¤í…œ ë©”ì¸ ëª¨ë“ˆ
ì‹œê³µê°„ ë°ì´í„° í•™ìŠµì„ ì´ìš©í•œ ë”¥ëŸ¬ë‹ ê¸°ë°˜ êµí†µì‚¬ê³  ìœ„í—˜ ì˜ˆì¸¡

Author: ì„œì¬ìš©
Project: ê°•ì›ë„ ì†Œë°©ë³¸ë¶€ ì‘ê¸‰êµ¬ì¡° ìˆ˜ìš” ì˜ˆì¸¡
Date: 2021-2023
"""

import sys
import os
import pandas as pd
import numpy as np
import torch
import warnings
from datetime import datetime
from pathlib import Path

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ ì„í¬íŠ¸
from src.emergency_data_processor import EmergencyDataProcessor
from src.tft_model import EmergencyDemandPredictor
from src.spatial_features import SpatialFeatureExtractor
from src.weather_integration import WeatherDataIntegrator
from src.visualization import EmergencyAnalyzer
from src.model_evaluation import ModelEvaluator
from config.settings import CONFIG

# ê²½ê³  ë©”ì‹œì§€ ìˆ¨ê¸°ê¸°
warnings.filterwarnings('ignore')

# ë””ë²„ê·¸ ë¡œê¹… ì„¤ì •
import logging
logging.basicConfig(level=logging.ERROR, format='ERROR: %(name)s:line_%(lineno)d - %(message)s')
logger = logging.getLogger(__name__)

class EmergencyForecastSystem:
    """ì‘ê¸‰êµ¬ì¡° ìˆ˜ìš” ì˜ˆì¸¡ ì‹œìŠ¤í…œ ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.config = CONFIG
        self.data_processor = EmergencyDataProcessor()
        self.spatial_extractor = SpatialFeatureExtractor()
        self.weather_integrator = WeatherDataIntegrator()
        self.predictor = EmergencyDemandPredictor(
            max_encoder_length=self.config['model']['encoder_length'],
            max_prediction_length=self.config['model']['prediction_length']
        )
        self.analyzer = EmergencyAnalyzer()
        self.evaluator = ModelEvaluator()
        
        logger.error("ì‘ê¸‰êµ¬ì¡° ìˆ˜ìš” ì˜ˆì¸¡ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
        
    def load_and_process_data(self):
        """ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
        logger.error("ë°ì´í„° ë¡œë“œ ì‹œì‘")
        
        # ê°•ì›ë„ ì†Œë°©ì¼ì§€ ë°ì´í„° ë¡œë“œ
        fire_data = self.data_processor.load_fire_department_data(
            self.config['data']['fire_department_path']
        )
        
        # ê³µê°„ì  íŠ¹ì„± ì¶”ê°€
        fire_data = self.spatial_extractor.add_spatial_features(fire_data)
        
        # ë‚ ì”¨ ë°ì´í„° í†µí•©
        fire_data = self.weather_integrator.integrate_weather_data(
            fire_data, self.config['data']['weather_path']
        )
        
        # ì‹œê³„ì—´ íŠ¹ì„± ìƒì„±
        processed_data = self.data_processor.create_time_series_features(fire_data)
        
        logger.error(f"ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ - ì´ {len(processed_data)}ê°œ ë ˆì½”ë“œ")
        return processed_data
        
    def train_model(self, data):
        """TFT ëª¨ë¸ í•™ìŠµ"""
        logger.error("TFT ëª¨ë¸ í•™ìŠµ ì‹œì‘")
        
        # í›ˆë ¨/ê²€ì¦ ë°ì´í„° ë¶„í• 
        train_data = data[data['date'] < self.config['data']['split_date']]
        val_data = data[data['date'] >= self.config['data']['split_date']]
        
        # ì‹œê³„ì—´ ë°ì´í„°ì…‹ ìƒì„±
        training_dataset = self.predictor.create_dataset(train_data)
        validation_dataset = self.predictor.create_dataset(val_data)
        
        # ë°ì´í„°ë¡œë” ìƒì„±
        train_dataloader = training_dataset.to_dataloader(
            train=True, batch_size=self.config['model']['batch_size']
        )
        val_dataloader = validation_dataset.to_dataloader(
            train=False, batch_size=self.config['model']['batch_size']
        )
        
        # TFT ëª¨ë¸ êµ¬ì¶• ë° í•™ìŠµ
        model = self.predictor.build_model(training_dataset)
        trainer = self.predictor.train_model(
            train_dataloader, val_dataloader, 
            max_epochs=self.config['model']['max_epochs']
        )
        
        logger.error("TFT ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")
        return model, trainer, validation_dataset

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    logger.error("ì‘ê¸‰êµ¬ì¡° ìˆ˜ìš” ì˜ˆì¸¡ ì‹œìŠ¤í…œ ì‹œì‘")
    
    # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    system = EmergencyForecastSystem()
    
    # ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
    data = system.load_and_process_data()
    
    # ëª¨ë¸ í•™ìŠµ
    model, trainer, val_dataset = system.train_model(data)
    
    # ëª¨ë¸ í‰ê°€
    predictions = system.predictor.predict_emergency_demand(val_dataset)
    metrics = system.evaluator.evaluate_predictions(predictions, val_dataset)
    
    # ê²°ê³¼ ì‹œê°í™”
    system.analyzer.create_comprehensive_report(predictions, metrics)
    
    logger.error("ì‘ê¸‰êµ¬ì¡° ìˆ˜ìš” ì˜ˆì¸¡ ì‹œìŠ¤í…œ ì‹¤í–‰ ì™„ë£Œ")
    print("ğŸš€ ì‘ê¸‰êµ¬ì¡° ìˆ˜ìš” ì˜ˆì¸¡ ì‹œìŠ¤í…œì´ ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤!")

if __name__ == "__main__":
    main()`,

            'emergency_data_processor.py': `"""
ê°•ì›ë„ ì†Œë°©ì¼ì§€ ë°ì´í„° ì „ì²˜ë¦¬ ëª¨ë“ˆ
ì‘ê¸‰êµ¬ì¡° ì¶œë™ ë°ì´í„°ì˜ ì‹œê³µê°„ì  íŠ¹ì„±ì„ ì¶”ì¶œí•˜ê³  ì •ì œ
"""

import pandas as pd
import numpy as np
import geopandas as gpd
from datetime import datetime, timedelta
import re
import logging

logger = logging.getLogger(__name__)

class EmergencyDataProcessor:
    """ì‘ê¸‰êµ¬ì¡° ë°ì´í„° ì „ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.spatial_features = []
        self.temporal_features = []
        self.categorical_mappings = {}
        
        logger.error("EmergencyDataProcessor ì´ˆê¸°í™” ì™„ë£Œ")
        
    def load_fire_department_data(self, file_path):
        """ê°•ì›ë„ ì†Œë°©ì¼ì§€ ë°ì´í„° ë¡œë“œ"""
        try:
            df = pd.read_csv(file_path, encoding='utf-8')
            logger.error(f"ì†Œë°©ì¼ì§€ ë°ì´í„° ë¡œë“œ - {len(df)}ê°œ ë ˆì½”ë“œ")
            
            # í•„ìˆ˜ ì»¬ëŸ¼ ê²€ì¦
            required_cols = ['incident_datetime', 'location', 'incident_type', 'response_time']
            missing_cols = set(required_cols) - set(df.columns)
            if missing_cols:
                raise ValueError(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_cols}")
            
            # ê¸°ë³¸ ì „ì²˜ë¦¬
            df = self._clean_basic_data(df)
            df = self._extract_temporal_features(df)
            
            logger.error("ì†Œë°©ì¼ì§€ ë°ì´í„° ê¸°ë³¸ ì „ì²˜ë¦¬ ì™„ë£Œ")
            return df
            
        except Exception as e:
            logger.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
    
    def _clean_basic_data(self, df):
        """ê¸°ë³¸ ë°ì´í„° ì •ì œ"""
        # ì¤‘ë³µ ì œê±°
        df = df.drop_duplicates()
        
        # ë‚ ì§œì‹œê°„ ë³€í™˜
        df['datetime'] = pd.to_datetime(df['incident_datetime'], errors='coerce')
        
        # ì˜ëª»ëœ ë‚ ì§œ ì œê±°
        df = df.dropna(subset=['datetime'])
        
        # ìœ„ì¹˜ ì •ë³´ ì •ì œ
        df['location'] = df['location'].str.strip()
        df = df[df['location'] != '']
        
        return df
    
    def _extract_temporal_features(self, df):
        """ì‹œê°„ì  íŠ¹ì„± ì¶”ì¶œ"""
        # ê¸°ë³¸ ì‹œê°„ íŠ¹ì„±
        df['year'] = df['datetime'].dt.year
        df['month'] = df['datetime'].dt.month
        df['day'] = df['datetime'].dt.day
        df['hour'] = df['datetime'].dt.hour
        df['minute'] = df['datetime'].dt.minute
        df['weekday'] = df['datetime'].dt.weekday
        df['day_of_year'] = df['datetime'].dt.dayofyear
        
        # íŒŒìƒ íŠ¹ì„±
        df['is_weekend'] = df['weekday'].isin([5, 6]).astype(int)
        df['is_holiday'] = df['datetime'].apply(self._is_korean_holiday)
        df['season'] = df['month'].apply(self._get_season)
        df['time_period'] = df['hour'].apply(self._get_time_period)
        
        # ìˆœí™˜ì  íŠ¹ì„± (ì‹œê°„ì˜ ì£¼ê¸°ì„± ë°˜ì˜)
        df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)
        df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)
        df['weekday_sin'] = np.sin(2 * np.pi * df['weekday'] / 7)
        df['weekday_cos'] = np.cos(2 * np.pi * df['weekday'] / 7)
        df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)
        df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)
        
        return df
    
    def _get_season(self, month):
        """ê³„ì ˆ ë¶„ë¥˜"""
        if month in [12, 1, 2]: return 'winter'
        elif month in [3, 4, 5]: return 'spring'
        elif month in [6, 7, 8]: return 'summer'
        else: return 'autumn'
    
    def _get_time_period(self, hour):
        """ì‹œê°„ëŒ€ ë¶„ë¥˜"""
        if 6 <= hour < 12: return 'morning'
        elif 12 <= hour < 18: return 'afternoon'
        elif 18 <= hour < 22: return 'evening'
        else: return 'night'
    
    def _is_korean_holiday(self, date):
        """í•œêµ­ ê³µíœ´ì¼ ì—¬ë¶€ íŒë‹¨ (ê°„ì†Œí™”)"""
        # ì‹¤ì œë¡œëŠ” ê³µíœ´ì¼ APIë‚˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš© ê¶Œì¥
        holidays = [
            (1, 1),   # ì‹ ì •
            (3, 1),   # ì‚¼ì¼ì ˆ
            (5, 5),   # ì–´ë¦°ì´ë‚ 
            (6, 6),   # í˜„ì¶©ì¼
            (8, 15),  # ê´‘ë³µì ˆ
            (10, 3),  # ê°œì²œì ˆ
            (10, 9),  # í•œê¸€ë‚ 
            (12, 25)  # ì„±íƒ„ì ˆ
        ]
        return (date.month, date.day) in holidays
    
    def create_time_series_features(self, df):
        """ì‹œê³„ì—´ ëª¨ë¸ë§ì„ ìœ„í•œ íŠ¹ì„± ìƒì„±"""
        # ì§€ì—­ë³„-ì‹œê°„ë³„ ì§‘ê³„
        df_ts = df.groupby(['location', 'date']).agg({
            'incident_type': 'count',  # ì¶œë™ ê±´ìˆ˜
            'response_time': ['mean', 'std'],  # í‰ê· /í‘œì¤€í¸ì°¨ ëŒ€ì‘ì‹œê°„
            'hour': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else x.mean(),  # ìµœë¹ˆ ì‹œê°„
            'is_weekend': 'max',
            'season': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else x.iloc[0]
        }).reset_index()
        
        # ì»¬ëŸ¼ëª… ì •ë¦¬
        df_ts.columns = ['location', 'date', 'emergency_count', 'avg_response_time', 
                        'std_response_time', 'peak_hour', 'is_weekend', 'season']
        
        # ê²°ì¸¡ì¹˜ ì²˜ë¦¬
        df_ts['std_response_time'] = df_ts['std_response_time'].fillna(0)
        
        # ì‹œê°„ ì¸ë±ìŠ¤ ìƒì„± (TFT ëª¨ë¸ìš©)
        df_ts = df_ts.sort_values(['location', 'date'])
        df_ts['time_idx'] = df_ts.groupby('location').cumcount()
        
        logger.error(f"ì‹œê³„ì—´ íŠ¹ì„± ìƒì„± ì™„ë£Œ - {len(df_ts)}ê°œ ë ˆì½”ë“œ")
        return df_ts

    def add_lag_features(self, df, target_col='emergency_count', lags=[1, 2, 3, 7]):
        """ì§€ì—° íŠ¹ì„± ì¶”ê°€"""
        for lag in lags:
            df[f'{target_col}_lag_{lag}'] = df.groupby('location')[target_col].shift(lag)
        
        # ë¡¤ë§ í†µê³„
        for window in [3, 7, 14]:
            df[f'{target_col}_rolling_mean_{window}'] = df.groupby('location')[target_col].rolling(
                window=window, min_periods=1
            ).mean().reset_index(0, drop=True)
            
            df[f'{target_col}_rolling_std_{window}'] = df.groupby('location')[target_col].rolling(
                window=window, min_periods=1
            ).std().reset_index(0, drop=True)
        
        logger.error("ì§€ì—° íŠ¹ì„± ë° ë¡¤ë§ í†µê³„ ì¶”ê°€ ì™„ë£Œ")
        return df
`,

            'tft_model.py': `"""
Temporal Fusion Transformer ëª¨ë¸ êµ¬í˜„
ì‘ê¸‰êµ¬ì¡° ìˆ˜ìš” ì˜ˆì¸¡ì„ ìœ„í•œ ë”¥ëŸ¬ë‹ ëª¨ë¸
"""

import torch
import torch.nn as nn
from pytorch_forecasting import TemporalFusionTransformer, TimeSeriesDataSet
from pytorch_forecasting.data import GroupNormalizer
from pytorch_forecasting.metrics import SMAPE, PoissonLoss, QuantileLoss
import pytorch_lightning as pl
from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint
import numpy as np
import logging

logger = logging.getLogger(__name__)

class EmergencyDemandPredictor:
    """TFT ê¸°ë°˜ ì‘ê¸‰ìˆ˜ìš” ì˜ˆì¸¡ ëª¨ë¸"""
    
    def __init__(self, max_encoder_length=168, max_prediction_length=24):
        self.max_encoder_length = max_encoder_length  # 1ì£¼ì¼(168ì‹œê°„) ê³¼ê±° ë°ì´í„°
        self.max_prediction_length = max_prediction_length  # 24ì‹œê°„ ì˜ˆì¸¡
        self.model = None
        self.trainer = None
        
        logger.error(f"TFT ì˜ˆì¸¡ê¸° ì´ˆê¸°í™” - encoder:{max_encoder_length}h, prediction:{max_prediction_length}h")
    
    def create_dataset(self, data):
        """ì‹œê³„ì—´ ë°ì´í„°ì…‹ ìƒì„±"""
        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        required_cols = ['time_idx', 'emergency_count', 'location']
        missing_cols = set(required_cols) - set(data.columns)
        if missing_cols:
            raise ValueError(f"í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_cols}")
        
        # ì •ì  ë³€ìˆ˜ (ì§€ì—­ë³„ ê³ ì • íŠ¹ì„±)
        static_categoricals = ['location']
        static_reals = []
        
        # ì•Œë ¤ì§„ ë¯¸ë˜ ë³€ìˆ˜ (ì˜ˆì¸¡ ì‹œì ì— ì•Œ ìˆ˜ ìˆëŠ” ë³€ìˆ˜)
        time_varying_known_categoricals = ['season', 'is_weekend']
        time_varying_known_reals = [
            'hour_sin', 'hour_cos', 'weekday_sin', 'weekday_cos', 
            'month_sin', 'month_cos'
        ]
        
        # ì•Œë ¤ì§€ì§€ ì•Šì€ ë¯¸ë˜ ë³€ìˆ˜ (ì˜ˆì¸¡ ëŒ€ìƒ)
        time_varying_unknown_reals = ['emergency_count', 'avg_response_time']
        
        # ì‹¤ì œ ë°ì´í„°ì— ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì‚¬ìš©
        def filter_existing_columns(cols, data_cols):
            return [col for col in cols if col in data_cols]
        
        time_varying_known_categoricals = filter_existing_columns(
            time_varying_known_categoricals, data.columns
        )
        time_varying_known_reals = filter_existing_columns(
            time_varying_known_reals, data.columns
        )
        time_varying_unknown_reals = filter_existing_columns(
            time_varying_unknown_reals, data.columns
        )
        
        # ì‹œê³„ì—´ ë°ì´í„°ì…‹ ìƒì„±
        training = TimeSeriesDataSet(
            data,
            time_idx="time_idx",
            target="emergency_count",
            group_ids=["location"],
            
            static_categoricals=static_categoricals,
            static_reals=static_reals,
            
            time_varying_known_categoricals=time_varying_known_categoricals,
            time_varying_known_reals=time_varying_known_reals,
            time_varying_unknown_reals=time_varying_unknown_reals,
            
            max_encoder_length=self.max_encoder_length,
            max_prediction_length=self.max_prediction_length,
            
            # ì •ê·œí™”
            target_normalizer=GroupNormalizer(
                groups=["location"], 
                transformation="softplus",
                center=True
            ),
            
            # ëˆ„ë½ ì‹œì  í—ˆìš©
            allow_missing_timesteps=True,
            
            # ìµœì†Œ ì˜ˆì¸¡ ê¸¸ì´
            min_prediction_length=1,
        )
        
        logger.error(f"ì‹œê³„ì—´ ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ - {len(training)}ê°œ ìƒ˜í”Œ")
        return training
    
    def build_model(self, training_dataset):
        """TFT ëª¨ë¸ êµ¬ì¶•"""
        # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •
        model_params = {
            'learning_rate': 0.01,
            'hidden_size': 64,
            'attention_head_size': 4,
            'dropout': 0.2,
            'hidden_continuous_size': 32,
            'output_size': 7,  # ë¶„ìœ„ìˆ˜ ì˜ˆì¸¡ì„ ìœ„í•œ ì¶œë ¥ í¬ê¸°
            'loss': QuantileLoss(),
            'log_interval': 10,
            'reduce_on_plateau_patience': 3,
            'weight_decay': 1e-5,
        }
        
        # ëª¨ë¸ ìƒì„±
        self.model = TemporalFusionTransformer.from_dataset(
            training_dataset,
            **model_params
        )
        
        logger.error(f"TFT ëª¨ë¸ êµ¬ì¶• ì™„ë£Œ - íŒŒë¼ë¯¸í„°: {sum(p.numel() for p in self.model.parameters()):,}")
        return self.model
    
    def train_model(self, train_dataloader, val_dataloader, max_epochs=50):
        """ëª¨ë¸ í•™ìŠµ"""
        # ì½œë°± ì„¤ì •
        early_stopping = EarlyStopping(
            monitor="val_loss",
            min_delta=1e-4,
            patience=10,
            verbose=False,
            mode="min"
        )
        
        checkpoint = ModelCheckpoint(
            save_top_k=1,
            monitor="val_loss",
            mode="min",
            filename="best-model-{epoch:02d}-{val_loss:.2f}"
        )
        
        # íŠ¸ë ˆì´ë„ˆ ì„¤ì •
        self.trainer = pl.Trainer(
            max_epochs=max_epochs,
            accelerator="auto",
            devices="auto",
            gradient_clip_val=0.1,
            callbacks=[early_stopping, checkpoint],
            enable_progress_bar=True,
            enable_model_summary=True,
        )
        
        # í•™ìŠµ ì‹¤í–‰
        logger.error("TFT ëª¨ë¸ í•™ìŠµ ì‹œì‘")
        self.trainer.fit(
            self.model,
            train_dataloaders=train_dataloader,
            val_dataloaders=val_dataloader
        )
        
        logger.error("TFT ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")
        return self.trainer
    
    def predict_emergency_demand(self, test_data):
        """ì‘ê¸‰ìˆ˜ìš” ì˜ˆì¸¡"""
        if self.model is None:
            raise ValueError("ëª¨ë¸ì´ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        
        # ì˜ˆì¸¡ ì‹¤í–‰
        predictions = self.model.predict(
            test_data, 
            mode="prediction",
            return_index=True,
            return_decoder_lengths=True,
            show_progress_bar=True
        )
        
        logger.error(f"ì˜ˆì¸¡ ì™„ë£Œ - ì˜ˆì¸¡ ìƒ˜í”Œ ìˆ˜: {len(predictions)}")
        return predictions
    
    def get_variable_importance(self, test_data):
        """ë³€ìˆ˜ ì¤‘ìš”ë„ ë¶„ì„"""
        interpretation = self.model.interpret_output(
            test_data.take(100),  # ìƒ˜í”Œ 100ê°œë§Œ ì‚¬ìš© (ì†ë„ ìµœì í™”)
            reduction="sum"
        )
        
        # ë³€ìˆ˜ ì¤‘ìš”ë„ ì¶”ì¶œ
        variable_importance = {
            'encoder_variables': interpretation['attention'],
            'decoder_variables': interpretation['static_variables'] if 'static_variables' in interpretation else {},
        }
        
        logger.error("ë³€ìˆ˜ ì¤‘ìš”ë„ ë¶„ì„ ì™„ë£Œ")
        return variable_importance
    
    def predict_with_confidence(self, test_data, confidence_levels=[0.1, 0.5, 0.9]):
        """ì‹ ë¢°êµ¬ê°„ì„ í¬í•¨í•œ ì˜ˆì¸¡"""
        predictions = self.predict_emergency_demand(test_data)
        
        # ë¶„ìœ„ìˆ˜ ê¸°ë°˜ ì‹ ë¢°êµ¬ê°„ ê³„ì‚°
        confidence_intervals = {}
        for level in confidence_levels:
            if isinstance(predictions, torch.Tensor):
                # ë¶„ìœ„ìˆ˜ ê³„ì‚°
                quantile_idx = int(level * (predictions.shape[-1] - 1))
                confidence_intervals[f'quantile_{level}'] = predictions[..., quantile_idx]
        
        return predictions, confidence_intervals
`,

            'spatial_features.py': `"""
ê³µê°„ì  íŠ¹ì„± ì¶”ì¶œ ëª¨ë“ˆ
ì§€ë¦¬ì  ì •ë³´ì™€ ë„ì‹œ í™˜ê²½ íŠ¹ì„±ì„ ë¶„ì„
"""

import pandas as pd
import numpy as np
import geopandas as gpd
from geopy.distance import geodesic
from sklearn.cluster import KMeans
import requests
import logging

logger = logging.getLogger(__name__)

class SpatialFeatureExtractor:
    """ê³µê°„ì  íŠ¹ì„± ì¶”ì¶œ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.region_clusters = None
        self.poi_data = None
        self.road_network = None
        
        logger.error("SpatialFeatureExtractor ì´ˆê¸°í™” ì™„ë£Œ")
    
    def add_spatial_features(self, df):
        """ê³µê°„ì  íŠ¹ì„± ì¶”ê°€ ë©”ì¸ í•¨ìˆ˜"""
        logger.error("ê³µê°„ì  íŠ¹ì„± ì¶”ê°€ ì‹œì‘")
        
        # ì¢Œí‘œ ì¶”ì¶œ (ì£¼ì†Œ â†’ ìœ„ê²½ë„)
        df = self._extract_coordinates(df)
        
        # ì§€ì—­ ë¶„ë¥˜
        df = self._classify_regions(df)
        
        # ë„ë¡œ ë° êµí†µ íŠ¹ì„±
        df = self._add_road_features(df)
        
        # ì¸êµ¬ ë°€ë„ ë° ë„ì‹œ íŠ¹ì„±
        df = self._add_urban_features(df)
        
        # POI(ê´€ì‹¬ì§€ì ) ê±°ë¦¬
        df = self._add_poi_distances(df)
        
        logger.error("ê³µê°„ì  íŠ¹ì„± ì¶”ê°€ ì™„ë£Œ")
        return df
    
    def _extract_coordinates(self, df):
        """ì£¼ì†Œì—ì„œ ìœ„ê²½ë„ ì¢Œí‘œ ì¶”ì¶œ"""
        # ê°„ì†Œí™”ëœ êµ¬í˜„ - ì‹¤ì œë¡œëŠ” geocoding API ì‚¬ìš©
        # ê°•ì›ë„ ì£¼ìš” ë„ì‹œ ì¢Œí‘œ ë§¤í•‘
        city_coords = {
            'ì¶˜ì²œ': (37.8813, 127.7299),
            'ì›ì£¼': (37.3422, 127.9202),
            'ê°•ë¦‰': (37.7556, 128.8961),
            'ë™í•´': (37.5247, 129.1143),
            'íƒœë°±': (37.1640, 128.9856),
            'ì†ì´ˆ': (38.2070, 128.5918),
            'ì‚¼ì²™': (37.4386, 129.1658),
        }
        
        def get_coordinates(location):
            for city, coords in city_coords.items():
                if city in str(location):
                    # ì‹¤ì œ ìœ„ì¹˜ì— ì•½ê°„ì˜ ë…¸ì´ì¦ˆ ì¶”ê°€ (ìƒì„¸ ìœ„ì¹˜ ì‹œë®¬ë ˆì´ì…˜)
                    lat = coords[0] + np.random.normal(0, 0.01)
                    lon = coords[1] + np.random.normal(0, 0.01)
                    return lat, lon
            # ê¸°ë³¸ê°’ (ì¶˜ì²œ)
            return 37.8813 + np.random.normal(0, 0.1), 127.7299 + np.random.normal(0, 0.1)
        
        coords = df['location'].apply(get_coordinates)
        df['latitude'] = [coord[0] for coord in coords]
        df['longitude'] = [coord[1] for coord in coords]
        
        logger.error("ì¢Œí‘œ ì¶”ì¶œ ì™„ë£Œ")
        return df
    
    def _classify_regions(self, df):
        """ì§€ì—­ ìœ í˜• ë¶„ë¥˜"""
        def classify_region_type(lat, lon):
            # ê°•ì›ë„ ì§€ì—­ íŠ¹ì„±ì— ë”°ë¥¸ ë¶„ë¥˜
            if lat > 38.0:  # ë¶ë¶€ (ì†ì´ˆ, ê³ ì„± ë“±)
                return 'coastal_north'
            elif lon > 128.5:  # ë™ë¶€ (ê°•ë¦‰, ë™í•´ ë“±)
                return 'coastal_east'
            elif lat < 37.3:  # ë‚¨ë¶€ (ì›ì£¼, ì˜ì›” ë“±)
                return 'inland_south'
            else:  # ì¤‘ë¶€ (ì¶˜ì²œ, í™ì²œ ë“±)
                return 'inland_central'
        
        df['region_type'] = df.apply(
            lambda row: classify_region_type(row['latitude'], row['longitude']), 
            axis=1
        )
        
        # ì§€ì—­ë³„ í´ëŸ¬ìŠ¤í„°ë§
        if len(df) > 10:
            coords = df[['latitude', 'longitude']].values
            n_clusters = min(8, len(df) // 5)  # ì ì ˆí•œ í´ëŸ¬ìŠ¤í„° ìˆ˜
            kmeans = KMeans(n_clusters=n_clusters, random_state=42)
            df['location_cluster'] = kmeans.fit_predict(coords)
        else:
            df['location_cluster'] = 0
        
        logger.error("ì§€ì—­ ë¶„ë¥˜ ì™„ë£Œ")
        return df
    
    def _add_road_features(self, df):
        """ë„ë¡œ ë° êµí†µ íŠ¹ì„± ì¶”ê°€"""
        # ë„ë¡œ ìœ í˜• ì¶”ì • (ì‹¤ì œë¡œëŠ” ë„ë¡œ ë„¤íŠ¸ì›Œí¬ API ì‚¬ìš©)
        def estimate_road_type(location):
            if 'ê³ ì†ë„ë¡œ' in str(location) or 'êµ­ë„' in str(location):
                return 'highway'
            elif 'ì‹œë‚´' in str(location) or 'ì¤‘ì‹¬ê°€' in str(location):
                return 'urban'
            elif 'ì‚°' in str(location) or 'ë†' in str(location):
                return 'rural'
            else:
                return 'suburban'
        
        df['road_type'] = df['location'].apply(estimate_road_type)
        
        # êµí†µ ë°€ë„ ì¶”ì •
        def estimate_traffic_density(region_type, road_type):
            density_map = {
                ('coastal_east', 'urban'): 0.8,
                ('inland_central', 'urban'): 0.7,
                ('coastal_north', 'highway'): 0.6,
                ('inland_south', 'suburban'): 0.4,
            }
            return density_map.get((region_type, road_type), 0.3)
        
        df['traffic_density'] = df.apply(
            lambda row: estimate_traffic_density(row['region_type'], row['road_type']),
            axis=1
        )
        
        logger.error("ë„ë¡œ íŠ¹ì„± ì¶”ê°€ ì™„ë£Œ")
        return df
    
    def _add_urban_features(self, df):
        """ë„ì‹œ í™˜ê²½ íŠ¹ì„± ì¶”ê°€"""
        # ì¸êµ¬ ë°€ë„ ì¶”ì • (í†µê³„ì²­ ë°ì´í„° ê¸°ë°˜ ê°„ì†Œí™”)
        population_density_map = {
            'coastal_east': 850,    # ê°•ë¦‰, ë™í•´ ë“±
            'inland_central': 650,  # ì¶˜ì²œ ë“±
            'coastal_north': 400,   # ì†ì´ˆ ë“±
            'inland_south': 300     # ì›ì£¼ ë“±
        }
        
        df['population_density'] = df['region_type'].map(population_density_map)
        
        # ê²½ì œ í™œë™ ì§€ìˆ˜
        economic_activity_map = {
            'coastal_east': 0.75,   # ê´€ê´‘ì—… í™œë°œ
            'inland_central': 0.70,  # í–‰ì •ì¤‘ì‹¬ì§€
            'coastal_north': 0.60,   # ì¤‘ê°„ ìˆ˜ì¤€
            'inland_south': 0.55     # ë†ì—… ì¤‘ì‹¬
        }
        
        df['economic_activity'] = df['region_type'].map(economic_activity_map)
        
        # ë„ì‹œí™” ì •ë„
        urbanization_map = {
            'urban': 0.9,
            'suburban': 0.6,
            'highway': 0.4,
            'rural': 0.2
        }
        
        df['urbanization_level'] = df['road_type'].map(urbanization_map)
        
        logger.error("ë„ì‹œ í™˜ê²½ íŠ¹ì„± ì¶”ê°€ ì™„ë£Œ")
        return df
    
    def _add_poi_distances(self, df):
        """ê´€ì‹¬ì§€ì (POI) ê±°ë¦¬ ê³„ì‚°"""
        # ì£¼ìš” ì‹œì„¤ê¹Œì§€ì˜ ê±°ë¦¬ (ë³‘ì›, ì†Œë°©ì„œ, ê²½ì°°ì„œ ë“±)
        major_facilities = {
            'hospital': [(37.8856, 127.7294), (37.3396, 127.9200)],  # ì£¼ìš” ë³‘ì›
            'fire_station': [(37.8800, 127.7280), (37.3400, 127.9180)],  # ì†Œë°©ì„œ
            'police_station': [(37.8820, 127.7300), (37.3410, 127.9190)]  # ê²½ì°°ì„œ
        }
        
        for facility_type, locations in major_facilities.items():
            distances = []
            for _, row in df.iterrows():
                incident_location = (row['latitude'], row['longitude'])
                min_distance = min(
                    geodesic(incident_location, facility_loc).kilometers
                    for facility_loc in locations
                )
                distances.append(min_distance)
            
            df[f'distance_to_{facility_type}'] = distances
        
        logger.error("POI ê±°ë¦¬ ê³„ì‚° ì™„ë£Œ")
        return df
`,

            'requirements.txt': `# ì‘ê¸‰êµ¬ì¡° ìˆ˜ìš” ì˜ˆì¸¡ ì‹œìŠ¤í…œ ì˜ì¡´ì„±

# ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬
torch==1.13.1
pytorch-lightning==1.8.6
pytorch-forecasting==0.10.3

# ë°ì´í„° ì²˜ë¦¬
pandas==1.5.3
numpy==1.24.3
geopandas==0.12.2
scikit-learn==1.2.2

# ì‹œê°í™”
matplotlib==3.7.1
seaborn==0.12.2
plotly==5.14.1
folium==0.14.0

# ì§€ë¦¬ ì •ë³´
geopy==2.3.0
shapely==2.0.1

# ì›¹ í¬ë¡¤ë§ ë° API
requests==2.30.0
beautifulsoup4==4.12.2

# ìœ í‹¸ë¦¬í‹°
tqdm==4.65.0
pyyaml==6.0
python-dotenv==1.0.0

# ì£¼í”¼í„° ë…¸íŠ¸ë¶
jupyter==1.0.0
ipywidgets==8.0.6

# í…ŒìŠ¤íŠ¸
pytest==7.3.1
pytest-cov==4.0.0

# ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§
tensorboard==2.12.3
wandb==0.15.3`,

            'settings.py': `"""
ì‘ê¸‰êµ¬ì¡° ìˆ˜ìš” ì˜ˆì¸¡ ì‹œìŠ¤í…œ ì„¤ì • íŒŒì¼
"""

import os
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬
PROJECT_ROOT = Path(__file__).parent.parent

# ì„¤ì • ë”•ì…”ë„ˆë¦¬
CONFIG = {
    # ë°ì´í„° ê²½ë¡œ
    'data': {
        'fire_department_path': PROJECT_ROOT / 'data' / 'raw' / 'gangwon_fire_log.csv',
        'weather_path': PROJECT_ROOT / 'data' / 'raw' / 'weather_data.csv',
        'poi_path': PROJECT_ROOT / 'data' / 'raw' / 'poi_locations.csv',
        'processed_path': PROJECT_ROOT / 'data' / 'processed',
        'split_date': '2022-01-01',  # í›ˆë ¨/ê²€ì¦ ë°ì´í„° ë¶„í•  ê¸°ì¤€
    },
    
    # ëª¨ë¸ í•˜ì´í¼íŒŒë¼ë¯¸í„°
    'model': {
        'encoder_length': 168,  # 1ì£¼ì¼ (168ì‹œê°„)
        'prediction_length': 24,  # 24ì‹œê°„ ì˜ˆì¸¡
        'batch_size': 32,
        'max_epochs': 100,
        'learning_rate': 0.01,
        'hidden_size': 64,
        'attention_heads': 4,
        'dropout': 0.2,
    },
    
    # ì „ì²˜ë¦¬ ì„¤ì •
    'preprocessing': {
        'min_samples_per_location': 30,  # ì§€ì—­ë³„ ìµœì†Œ ìƒ˜í”Œ ìˆ˜
        'outlier_threshold': 3.0,  # ì´ìƒì¹˜ ì„ê³„ê°’ (Z-score)
        'lag_features': [1, 2, 3, 7, 14],  # ì§€ì—° íŠ¹ì„±
        'rolling_windows': [3, 7, 14, 30],  # ë¡¤ë§ ìœˆë„ìš°
    },
    
    # ì‹œê°í™” ì„¤ì •
    'visualization': {
        'figure_size': (12, 8),
        'dpi': 300,
        'style': 'seaborn-v0_8-darkgrid',
        'palette': 'viridis',
    },
    
    # ë¡œê¹… ì„¤ì •
    'logging': {
        'level': 'ERROR',
        'format': 'ERROR: %(name)s:line_%(lineno)d - %(message)s',
        'file_path': PROJECT_ROOT / 'logs' / 'emergency_forecast.log',
    },
    
    # API ì„¤ì •
    'api': {
        'weather_api_key': os.getenv('WEATHER_API_KEY'),
        'maps_api_key': os.getenv('MAPS_API_KEY'),
        'geocoding_api_key': os.getenv('GEOCODING_API_KEY'),
    },
    
    # ì„±ëŠ¥ ì„¤ì •
    'performance': {
        'n_jobs': -1,  # ë³‘ë ¬ ì²˜ë¦¬ ì½”ì–´ ìˆ˜
        'random_seed': 42,
        'gpu_memory_fraction': 0.8,
    }
}

# í™˜ê²½ë³„ ì„¤ì • ì˜¤ë²„ë¼ì´ë“œ
if os.getenv('ENV') == 'production':
    CONFIG['model']['max_epochs'] = 200
    CONFIG['preprocessing']['min_samples_per_location'] = 100
elif os.getenv('ENV') == 'development':
    CONFIG['model']['max_epochs'] = 10
    CONFIG['preprocessing']['min_samples_per_location'] = 5

# ë””ë ‰í† ë¦¬ ìƒì„±
for path_key in ['processed_path']:
    os.makedirs(CONFIG['data'][path_key], exist_ok=True)

os.makedirs(CONFIG['logging']['file_path'].parent, exist_ok=True)`
        };

        function loadFile(filename) {
            const content = fileContents[filename] || '// íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.';
            
            // í™œì„± íƒ­ ì—…ë°ì´íŠ¸
            document.getElementById('active-tab').textContent = filename;
            
            // ì½”ë“œ ë‚´ìš© ì—…ë°ì´íŠ¸
            document.getElementById('code-content').textContent = content;
            
            // ë¼ì¸ ë²ˆí˜¸ ì—…ë°ì´íŠ¸
            const lines = content.split('\\n').length;
            let lineNumbers = '';
            for (let i = 1; i <= lines; i++) {
                lineNumbers += i + '<br>';
            }
            document.getElementById('line-numbers').innerHTML = lineNumbers;
            
            // ì‹ íƒìŠ¤ í•˜ì´ë¼ì´íŒ… ì ìš©
            hljs.highlightAll();
            
            console.log(\`ERROR: file_loader.js:line_\${new Date().getSeconds()} - \${filename} íŒŒì¼ ë¡œë“œë¨\`);
        }

        function toggleFolder(folderId) {
            const folder = document.getElementById(folderId + '-folder');
            if (folder.classList.contains('hidden')) {
                folder.classList.remove('hidden');
            } else {
                folder.classList.add('hidden');
            }
            console.log(\`ERROR: folder_toggle.js:line_\${new Date().getSeconds()} - \${folderId} í´ë” í† ê¸€ë¨\`);
        }

        function searchFiles() {
            const query = prompt('íŒŒì¼ ê²€ìƒ‰ (Ctrl+P):');
            if (query) {
                const files = Object.keys(fileContents);
                const matches = files.filter(file => 
                    file.toLowerCase().includes(query.toLowerCase())
                );
                
                if (matches.length > 0) {
                    loadFile(matches[0]);
                    alert(\`\${matches.length}ê°œ íŒŒì¼ ë°œê²¬: \${matches.join(', ')}\`);
                } else {
                    alert('ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.');
                }
            }
            console.log(\`ERROR: file_search.js:line_\${new Date().getSeconds()} - íŒŒì¼ ê²€ìƒ‰ ì‹¤í–‰ë¨\`);
        }

        // í‚¤ë³´ë“œ ë‹¨ì¶•í‚¤
        document.addEventListener('keydown', function(event) {
            if (event.ctrlKey && event.key === 'p') {
                event.preventDefault();
                searchFiles();
            }
        });

        // ì´ˆê¸° íŒŒì¼ ë¡œë“œ
        document.addEventListener('DOMContentLoaded', function() {
            hljs.highlightAll();
            console.log("ERROR: emergency_code_analysis.js:line_456 - ì‘ê¸‰êµ¬ì¡° ì½”ë“œ ë¶„ì„ ì‹œìŠ¤í…œ ë¡œë“œ ì™„ë£Œ");
        });
    </script>
</body>
</html>